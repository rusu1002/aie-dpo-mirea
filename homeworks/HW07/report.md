# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите): S07-hw-dataset-01.csv, S07-hw-dataset-02.csv, S07-hw-dataset-03.csv

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9), после удаления sample_id: (12000, 8)
- Признаки: все числовые (float64/int64)
- Пропуски: нет
- "Подлости" датасета: Числовые признаки в разных шкалах. Необходимо масштабирование.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4), после удаления sample_id: (8000, 3)
- Признаки: все числовые
- Пропуски: нет
- "Подлости" датасета: Нелинейная структура, выбросы, лишний шумовой признак

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000, 5), после удаления sample_id: (15000, 4)
- Признаки: все числовые
- Пропуски: нет
- "Подлости" датасета: Кластеры разной плотности, фоновый шум

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: Использован StandardScaler для масштабирования всех признаков; пропусков не обнаружено, поэтому SimpleImputer не применялся; категориальных признаков нет, поэтому кодирование не требовалось; конвейер: Pipeline([('scaler', StandardScaler())]).
- Поиск гиперпараметров:
  - KMeans: k от 2 до 20 (включительно)
  - DBSCAN: eps = [0.3, 0.5, 0.8, 1.0, 1.2, 1.5, 2.0, 2.5, 3.0], min_samples = [3, 5, 10, 15, 20]
  - Agglomerative: k от 2 до 20, linkages = ['ward', 'complete', 'average']
  - Критерий выбора лучшего: silhouette score (выбиралась конфигурация с максимальным значением silhouette)
- Метрики: silhouette_score, davies_bouldin_score, calinski_harabasz_score (Для DBSCAN метрики считались только на non-noise точках. Доля шума выводилась отдельно)
- Визуализация: PCA(2D)

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

- KMeans (Поиск оптимального `k` в диапазоне 2-20, фиксировали `random_state=80`, `n_init='auto'`)
- DBSCAN (`eps=[0.3, 0.5, 0.8, 1.0, 1.2, 1.5, 2.0, 2.5, 3.0]`, `min_samples=[3, 5, 10, 15, 20]`, учет доли шума и метрики на non-noise точках)
- AgglomerativeClustering (Поиск по `k=list(range(2, 21))`, `linkage=["ward", "complete", "average"]`)

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: DBSCAN с eps=2.0, min_samples=3
- Метрики (silhouette / DB / CH): silhouette=0.522, davies_bouldin=0.685, calinski_harabasz=11787.0
- Если был DBSCAN: 0.0% (все точки в кластерах)
- Коротко: Все три алгоритма дали идентичные результаты, но DBSCAN предпочтительнее, так как не требует задания числа кластеров заранее и автоопределил 2 кластера. Структура данных явная и хорошо разделимая.

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN с eps=0.8, min_samples=15
- Метрики (silhouette / DB / CH): silhouette=0.545, davies_bouldin=0.472, calinski_harabasz=135.0
- Если был DBSCAN: 3.8% (в данных есть выбросы)
- Коротко: DBSCAN показал значительно лучшие метрики, чем KMeans (silhouette 0.545 против 0.307), что подтверждает его преимущество для нелинейных структур. Успешно выделил выбросы как шум.

### 4.3 Dataset C

- Лучший метод и параметры: AgglomerativeClustering с k=2, linkage='average'
- Метрики (silhouette / DB / CH): silhouette=0.425, davies_bouldin=0.814, calinski_harabasz=8.9
- Если был DBSCAN: 0.1% (в лучшем случае. Кластеры разной плотности провоцируют ошибки DBSCAN)
- Коротко: Agglomerative показал лучшие метрики, чем DBSCAN. Иерархический подход менее чувствителен к локальной плотности.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему?
    - KMeans "ломается" на Dataset B (`S07-hw-dataset-02.csv`), из-за нелинейной структуры данных, с которой KMeans (основанный на расстояниях до центроидов) плохо справляется.
- Где DBSCAN/иерархическая кластеризация выигрывают и почему?
    - DBSCAN выигрывает на Dataset B: благодаря способности находить кластеры произвольной формы и выделять выбросы как шум.
- Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)?
    - Масштабирование (критично для Dataset A (`S07-hw-dataset-01.csv`) с разными шкалами), плотность кластеров (определяющий фактор для выбора алгоритма), выбросы (влияют на метрики и требуют специальной обработки в DBSCAN).

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка устойчивости: проведен тест на датасетах - 5 запусков KMeans с разными random_state (42, 142, 242, 342, 442).
- Результаты:
    Dataset 01: средний ARI = 1.000, std(silhouette) = 0.0000
    Dataset 02: средний ARI = 0.9974, std(silhouette) = 0.0000
    Dataset 03: средний ARI = 0.9997, std(silhouette) = 0.0000
- Вывод: KMeans показывает высокую устойчивость на всех датасетах. Практически идентичные разбиения при разных инициализациях. Это говорит о том, что кластеры хорошо разделены и алгоритм стабильно сходится к одному решению.

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - профили признаков (средние/медианы) - определены признаки, которые сильнее всего отличаются от общего среднего по датасету.
- Для Dataset A: Кластер 0 характеризуется умеренными значениями признаков, кластер 1: имеет экстремальные значения. Кластеры разделяются по масштабу значений - один кластер средний, другой экстремальный.
- Для Dataset B: Кластер 0: низкий x1 (-0.18), высокий x2 (0.69). Кластер 1: высокий x1 (1.13), низкий x2 (-0.20). Четкое противоположное разделение по двум основным признакам (x1 и x2). Шумовой признак z_noise показывает минимальные различия.
- Для Dataset C: Кластер 0: максимальные значения x1 и x2 (6.60 и 5.88). Кластер 1: низкий x2 (-3.58), умеренный x1 (2.61). Кластер 2: низкие значения x1 (-2.86) и f_corr (-1.20). Сложная структура с тремя различными профилями: максимальные значения, противоречивые значения (высокий x1, низкий x2), минимальные значения.

## 6. Conclusion

KMeans хорош для сферических кластеров, DBSCAN - для произвольных форм и работы с выбросами, Agglomerative - для кластеров разной плотности. Метрики качества должны учитывать особенности алгоритмов. Выбор "лучшего" алгоритма зависит от структуры данных. Простые разделимые кластеры - любой алгоритм работает хорошо. Нелинейные структуры - DBSCAN предпочтительнее. Разная плотность - Agglomerative лучше.